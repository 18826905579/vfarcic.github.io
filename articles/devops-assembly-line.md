# Managing And Maintaing DevOps Assembly Line

Let's start with setting the record straight. There is no such thing as **DevOps Assembly Line**. I invented it by replacing **Software** with **DevOps**. Why did I do that? Because everything needs to put the word DevOps to be popular. Saying software assembly lines is boring. It sounds like something you already know, or at least you heard or it. Nevertheless, everything changes, and software assembly lines are not an exception. So, in the spirit of self-marketing, the title contains **DevOps** as a way to attract your attention. Still, from now on, I'll call it what it is. It'll be **software assembly line**.

## What Is (Software) Assembly Line?

To understand software assembly line, we need to understand manufacturing assembly line first. After all, we (software industry) based a lot of our practices on manufacturing industry. That is terribly wrong, but that's where most of us are, so let's see what does it mean in manufacturing.

Manufacturing assembly line can be described with the sentence that follows.

> "Manufacturing process in which parts are added in sequence until the final assembly is produced."

That sounds straightforward. Actually, it's so easy to understand that many thought that should be the way to assemble software. Add the parts in sequence from gathering requirements, all the way until it's deployed to production. Yippee! We got a process.

The problem is that manufacturing process differs from software development in one key aspect.

> "The goal of the manufacturing assembly line is to mass-produce a product with the same specifications and quality."

We do not have such goals. We are trying to produce a **single** product with a **repeatable process**. We do not make many copies of the same product (excluding those still delivering CDs and floppy disks to their desktop customers). At least, not in a physical form.

Every release is a different product. If that's not your case, and if you do make the same release over and over again, you are probably confused and choose the wrong industry.

All that is not to say that there is nothing to be learned from manufacturing assembly line. It features a repeatable process. Our processes should be repeatable as well. However, almost every manufacturing assembly line involves automation and manual labour. Ours should because we do not deal with physical world (everything are bytes). We can have a truly automated process, after the creative tasks end. And that leads me to yet another very important difference.

In manufacturing, considerable investment in time, people, and money goes into manufacturing while the design is usually much cheaper. We do, for example, need to design a car, but that is only a fraction of the cost. Producing it is where the real expense lies. In sooftware, design is almost entire cost of a release. Now, I need to clarify that by design, I want to say creative and not repeatable work that involves not only brainstorming of a solution, but also coding. Every feature we deliver is a result of a huge effort in creative tasks, and almost no effort to move it (after a committ) through the assembly which, in this context, means building, testing, deploying, and other repetitive tasks. At least, that's how it should be, even though in many cases its not.

We tend to employ an army of people dedicated to work manually on repetitive tasks (e.g., manual testing, deployments, etc). That is, kind of silly given that we are in business of writing software that does things and helps others in their daily lives. And yet, we are somehow better at creating software for others, than software that will help us.

But, I might have moved too fast. Let's go back in history and find out how we got where we are, and where should we go next.

## Waterfall Assembly Line

A long time ago in a galaxy far, far away, someone came up with a brilliant idea. "Why don't we do the same thing as manufacturing. We'll design a linear process that will be bullet-proof and will result in high-quality software being delivered to our customers fast." Now, for the sake of clarity, the idea came from Winston W. Royce as a description of a flawed, non-working model. But, be it as it may, we adopted it nevertheless and we started calling it waterfall. So, how does it work?

The process, in spite some variations, is linear. Analysts figure out what users need. They write specificatins and give them to developers. They write code that make those requirements a working software. They, in turn, are not to be trusted, so they pass it on to testers, that validate the software against the requirements. Once testers are finished, they deliver it to operators, who install that software in production. Just to be on the safe side, the last stage is maintenance. Just as cars sometimes mallfunction, our software often contains some undersirable effects which are fixed after its delivered to its users. The whole process would take only a couple of years or, if we're very good, sometimes only six months.

The only problem with the Waterfall process and its assembly line is that **it never worked**. And yet, we were repeating it over and over again. We do a project, and it fails either by not having sufficient quality, or by being more expensive, or by missing deadline (by months or years), or (the most common outcome) by not delivering things that users want. The first project would fail, and we'd to the second using the same process. When the second failed, we'd do the third. And so on and so forth until we retire. Every once in a while, we would be successful. But, those were either exceptions or we'd "fake" the plan to make sure that it works. By faking, I mean double the estimates and rewrite the requirements so that we can say "look, we delivered on time, and it's what you want". **What users wanted was in most cases not what users needed.**

We were not learning from our mistakes. The process was flaved and even when a project was considered a success, it was only because we did not follow the process. When I look back at those times, I can only conclude that we were all insane. At least, according to Einstein.

> "Insanity Is Doing the Same Thing Over and Over Again and Expecting Different Results" -- Albert Einstein

There were quite a few problems with the whole process. First of all, the duration. We cannot expect to work on something for months, or even years, before we deliver that something. Remember, we are not manufacturing identical copies. We are not producing cars where an error in design results in thousands of faulty cars being delivered and never to be fixed. We are delivering bytes that can change whenever we want and re-delivered to all users in no time.

The second reason for the failure of the waterfall process is that it was impossible to make it linear. We cannot expect analysists to know in advance all the features users want. We couldn't expect developers to work for months without producing bugs or, more importantly, not to make mistakes from the start and, at the end of their work, to expect them not to go back to the beginning due to those mistakes. Testers were supposed to confirm that our software works flawelessly, and not to return with hundreds or thousands of bug reports and missinterpreted requirements. If that was not our expectation, why were testers involved only after developers produce months or years all the faulty software? It gets worse. After the testing stage, we'd give it to operators, only to discover that, after the software is deployed, it does not work correctly and it needs to go back to developers and, consequenty, to testers. Finally, if the system worked well, why did we have months of maintenance? We do not return cars because there is no wheel in them but because there is a problem caused by driving thousands of kilometers.

Even though waterfall process tried to create an equivalent to the manufacturing assembly line, it went into the opposite direction. If anything, waterfall is closer to salve labour. **You have a tight control over everything and everyone, the process is mostly manual, and everyone dislikes you.** Waterfall is equivalent to pre-industrial revolution. Or, to find even better parallel, to the way egyptians built pyramids. A lot of managers overview the workforce working on implementing a multi-year plan that is likely going to be delayed, require more slaves, or crumble. There was no incentive for automation, and therefore, for an assembly line. Everything could be fixed by finding more people to work.

This brings me to the main problem.

## The Tools Used In Software Development

We tend to use a lot of tools and they differ from one role to another. Analysts might use Microsoft Word, Google Docs, or Markdown. Developers spend most of their time writing code in Visual Studio Code, IntelliJ, or Eclipse (only to name a few). Testers tend to look at stats in SonarQube and they might write some automated tests with, let's say, Selenium. Operators love VMWare, Docker, Kubernetes, OpenStack, and other tools that help them do their work. And those in charge of maintenance also have their favourte tools.

Using tools is not a problem per-se. The real issue is that we are mixing the tools and using them in inappropriate places. We can split them into those that require creative work (e.g., coding, writing stories, and so on) and those that do the repetitive steps. The former should be used while designing the solution, while the latter should be part of the assembly line. It is important to understand that the **assembly line is all about automation, and not the creative work**. We expect to have an assembly line in which we can say "stop the process, I need to write a test" or "pause everything, I need get an understanding of that weird result in SonarQube".

## Agile And DevOps Processes

After a lot of missery and suffering introduced through Waterfall, we got Agile and, later on, DevOps. The idea is simple, even though the two implemented it differently. Form a small and self-sufficient team capable of delivering a new set of features in each short iteration. The time of delivery changed from months, or even years, to weeks, and sometimes even days or hours. The major difference between Agile and DevOps, is that the former forgot to invite expertise from the second half of the software development lifecycle. Even though that was never officially prescribed, Agile teams forgot that they do need operational, infrastructure, and maintenance knowledge if they are to deliver features "for real". They would often say, "we're finished and we are moving into the next spring", even though there was a lot of work left to be done by others. DevOps remedies that by trying to form a truly self-sufficient teams that are in charge of everything, from requirements to deploying to production and maintaining software. Nevertheless, I'll assume that both types of teams are the same for the rest of this narrative.

Those self-sufficient teams decided that iterations should be short (e.g., weeks, or even days), so they had to move fast. Analysists (product owners?) would come up with the requirements for the upcoming sprint and pass it to developers. Developers would write their code and pass it to testers. Testers would pass it to operators. Operators would deploy to production and leave it to maintainers. Each of those handovers could fail and when that happens, the process would start over.

The problem with the process is that it is not essentially different from waterfall, except that an iteration shrinked from months or years, to weeks or days. Nevertheless, the problem of coupling creative design work with repetitive tasks of an assembly line was still mived. There is no place for creativity in an assembly line. Ask any factory worker and you'll get the same response. Assembly line is supposed to be fast and reliably and we accomplish that through repetition. If a worker in a factory would stop to think whether he liked the color of the new car or it should be better of with a sliglhy lighter shade, the whole process would break. That does not mean that a worker cannot stop the assembly line. It can (at least those in Toyota), but only if there is an issue that prevents repetability and quality of the outcome.

The result of applying some of the assembly line processes is continuous delivery or continuous deployment.

## Continuous Delivery Or Deployment

The goal of a continuous delivery (CD) or a continuous deployment (CDP) pipeline is simple to explain, but difficult to implement. **Every commit to a specific branch (e.g., master) is moved through a fully automated process that results in a new release being ready for deployment to production (CD) or being installed in production (CDP)**. The key words in that sentence are **fully automated process**. That means that there is no place for humans after that commit. Whatever manual work has to done, it needs to be done before the pipeline starts. There should be some tests, so write them in advance. There should be some modifications to the deployment script, write it in advance. And so on and so forth. Because, the moment a developer pushes new code, all manual work related to it must be finished. If you do not feel you can do your job in that fashion, that you cannot be proactive, maybe you should step down and let others take over. Or, admit your deficiencies and learn how to operate in this new world.

The only way to be effectively proactive during this "creative" stage is to define everything as code. Tests must be expressed as code, infrastructure needs to be defined as code, deployments need to be written as code, and so on and so forth. **Everything as code** is the new mantra. Enough time passed for us to realize that there is no place for non-coders in softwre industry. If you work with software, you code. It does not matter whether you are the "Jack of all trades" or you are specialized. Whatever you do, be it testing, developing, deploying, monitoring, or any other type of tasks, you have to write code. That's the reality of today's market and if you do not think that you can do that, there's still time to change your profession and become a doctor, a lawyer, or a truck driver.

During this creative pre-commit phase, we use tools that are quite different than the tools used during the pipeline. I do not care whether that's IntelliJ, VS Code, Vi, Eclipse, MS Project, or any other tool through which you use the creative side of your brain. As long as you do the job in advance, you're being proactive, and you can express it through code, you're doing fine. Opppsss... I forgot one important element. You need to finish whatever you have to do before a new commit is pushed to the master branch.

All those of you that were involved in manual processes during the latter phases of the software lifecycle need to move to the left, or move out. You need to learn how to be proactive and do the work in advance. We do not have time to wait for you. Lean time is not acceptable any more nor it is allowed to just throw things over the wall to others. Those days are gone and now we are expected to deliver fast, often multiple times a day. Such speed cannot be accomplished if there are **human blockers** in the process.

Once the pipeline starts, machines take over. A pipeline executed through one of the CD tools (e.g., Jenkins) will use a completelly different set of tools than those you used during the creative phase. Those can be SonarQube, Selenium, Kubernetes, Docker, VMWare, Git, and many others. What they all have in common is that they do not require humans (in this phase) and they do something. That something can be many things and the only important thing is their exit code. Each step is either successfull and the pipeline moves to the next one, or it fails and the execution of the pipeline stops. There is no gray area. There is no space for "we use SonarQube but we do not fail builds when certain thresholds are reached". The result of an execution of a pipeline is black and white. It's like **Schrödinger's cat**. While it's running, it can be dead or alive. Only when we open the lid (receive notifications) can we know the outcome. Or, to be more precise, we hear only about dead cats. There are no notifications telling us about those who survived, only about those that failed.

We accomplish removal of human tasks from the assembly pipeline through some kind of an executor. Jenkins is one of those. It is most commonly used CD tool in the market and the community, as well as enterprise offerings around it recognized the need for constant improvements. Once we employ an executor or, to be more precise, tasks orchestrator, it takes over the execution of all the tasks that involve the tools and logic that comprises the assembly pipeline.

Still, assuming that we do choose Jenkins, we might need to rewire our brains to the new processes and get rid of the legacy line of thinking. For one, there should be only one assembly pipeline per repository. We were thought for too long that the assembly should refrect our internal organization within the company. So, we ended up with many Freestyle jobs, one for each group involved in the lifecycle of the application. Instead of having a single pipeline for each repository (application), we were creating many smaller ones. One would be dedicated to developers working on a project. The other would be owned by testers. The third would be in the hands of operators. And so on, and so forth. The problem with that approach is that it relfects our, often ineffective and missunderstood internal human organization. Such divided pipeline does not make sense if we are to automate the whole process. An application resides inside a single repository and it contains a single pipeline that moves it through all the assembly steps. From the logical perspective, that is the only process that makes sense. Everything else was designed only to fuel our internal silos.

## Where Are We Today?

Freestyle jobs, when they were created over ten years ago, have to many problems. I can't say that they were designed badly at the time, but that the industry moved to new processes. They are not stored in version control and they do not represent a simple logic applied to the full lifecycle of an application. Moreover, the do not provide the full view of the assembly line nor do they scale. Most importantly, Frestyle jobs do not adhere to everything as code logic. Simply put, they are legacy and yet many still cling onto them. One of the reasons for that is inability to write code. Too many people are used to click-click-click way of working thinking that a complext pipeline can be defined and maintained by filling in endless number of fields and selecting values from drop-down lists. If that's your view of where the industry is today, you do not deserve to work in it.

Instead of Frestyle jobs, now we have Jenkins Pipelines. They are defined as code as stored in Jenkinsfile residing in the same repository as the code of the application that is being moved through the assembly. On top of other benefits, given that a singlke Jenkins Pipeline represent the whole flow of an application, we are finally able to represent it visually in a simple and easy to understand way through the Blue Ocean plugin.

Given that Jenkins Pipeline is code like any other, we should follow the best practices that we normally apply to code. Among others, Jenkinsfile should be simple and allow us to easily navigate through the flow. Jenkinsfile is not supposed to be hundreds of lines of code, just as the main function of your application hoppefully isn't big. It should be too simple eaither since it does need to allow us to navigate through the steps, or groups of steps, without the need to open other files. That means that a single line like `runPipeline()` is not a good idea either. We need to balance simplicity, readability, and navigation through the flow. For that reason, we got Shared Libraries.

Jenkins Pipeline Shared Libraries follow the same principle as shared libraries in any other application. Just as your application probably consists of a combination of public and private libraries, Jenkinsfile does the same. Publicly available steps are equivalent of public libraries you use (e.g., JUnit). On the other hand, just as you have common private code used across multiple applications, Jenkins has Shared Libraries. They reside in a separate code repository and can be invoked whenever a job needs them.

The introduction of Jenkins Pipelines, BlueOcean, Shared Libraries, and many other tools is only the part of the story. It would be follish to think that it's enough to concentrate on a single tool for all your CD and CDP processes. Jenkins is an orchestrator of the steps that comprise a pipeline. We need to make right choices about the tools that will be used in those steps as well as how we're going to run Jenkins and its agents.

Specifically, we have to solve the problem of scale. Sooner or later, we'll need more Jenkins servers and we'll need to manage all our agents which over time usually increase in number and variety.

TODO: Continue from http://vfarcic.github.io/devops-assembly/index.html#/7/9
